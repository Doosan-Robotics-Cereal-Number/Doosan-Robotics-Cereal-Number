"""
ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ëª¨ë“ˆ
- ë§ˆì´í¬ ë…¹ìŒ
- TTS ìŒì„± ì¶œë ¥
"""

import pyaudio
import wave
import os
import webrtcvad
import collections
from gtts import gTTS
from playsound import playsound


def record_audio(duration=5, filename="temp_record.wav"):
    """
    ë§ˆì´í¬ë¡œ ìŒì„± ë…¹ìŒ

    Args:
        duration: ë…¹ìŒ ì‹œê°„ (ì´ˆ)
        filename: ì €ì¥í•  íŒŒì¼ëª…

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000

    p = pyaudio.PyAudio()

    print(f"\nğŸ¤ {duration}ì´ˆê°„ ë…¹ìŒ ì‹œì‘...")

    stream = p.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )

    frames = []

    for i in range(0, int(RATE / CHUNK * duration)):
        data = stream.read(CHUNK)
        frames.append(data)

    print("âœ… ë…¹ìŒ ì™„ë£Œ!")

    stream.stop_stream()
    stream.close()
    p.terminate()

    # WAV íŒŒì¼ë¡œ ì €ì¥
    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    return filename


"""
VAD (Voice Activity Detection)
- 20ms (0.02ì´ˆ)ë§ˆë‹¤ ë§ˆì´í¬ ë°ì´í„° ì²´í¬
- ì‚¬ëŒì´ ë§í•˜ê³  ìˆë‚˜ íŒë‹¨
- ì¹¨ë¬µ 1.5ì´ˆ ì§€ì† -> ë…¹ìŒ ì¢…ë£Œ 
0"""
def record_audio_vad(filename="temp_record.wav", silence_duration=1.5, timeout=10):
    """
    VADë¥¼ ì‚¬ìš©í•œ ë™ì  ìŒì„± ë…¹ìŒ
    ì‚¬ëŒì´ ë§ì„ ëë‚´ë©´ (ì¹¨ë¬µ ê°ì§€) ìë™ìœ¼ë¡œ ë…¹ìŒ ì¢…ë£Œ

    Args:
        filename: ì €ì¥í•  íŒŒì¼ëª…
        silence_duration: ì¹¨ë¬µìœ¼ë¡œ íŒë‹¨í•  ì‹œê°„ (ì´ˆ)
        timeout: ìŒì„± ì‹œì‘ ëŒ€ê¸° ì‹œê°„ (ì´ˆ), ì´ ì‹œê°„ ì•ˆì— ë§ ì•ˆ í•˜ë©´ None ë¦¬í„´

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ, íƒ€ì„ì•„ì›ƒ ì‹œ None
    """
    # === ì„¤ì • ===
    RATE = 16000  # ìƒ˜í”Œë§ ë ˆì´íŠ¸ (VADëŠ” 8000, 16000, 32000ë§Œ ì§€ì›)
    CHUNK = 320   # 20ms ë¶„ëŸ‰ (16000 * 0.02 = 320)
    FORMAT = pyaudio.paInt16
    CHANNELS = 1

    # === VAD ì´ˆê¸°í™” ===
    # mode: 0(ê°€ì¥ ê´€ëŒ€)~3(ê°€ì¥ ì—„ê²©)
    # 3 = í™•ì‹¤í•œ ìŒì„±ë§Œ ì¸ì‹ (ë°°ê²½ ì†ŒìŒ ë¬´ì‹œ)
    vad = webrtcvad.Vad(3)

    # === PyAudio ì´ˆê¸°í™” ===
    p = pyaudio.PyAudio()
    stream = p.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )

    print(f"\nğŸ¤ ìŒì„±ì„ ê°ì§€í•˜ë©´ ë…¹ìŒì´ ì‹œì‘ë©ë‹ˆë‹¤... (íƒ€ì„ì•„ì›ƒ: {timeout}ì´ˆ)")

    frames = []  # ë…¹ìŒ ë°ì´í„° ì €ì¥
    speech_detected = False  # ìŒì„±ì´ ì‹œì‘ëëŠ”ì§€
    silence_chunks = 0  # ì—°ì† ì¹¨ë¬µ í”„ë ˆì„ ì¹´ìš´íŠ¸
    silence_threshold = int(silence_duration * RATE / CHUNK)  # ì¹¨ë¬µìœ¼ë¡œ íŒë‹¨í•  í”„ë ˆì„ ìˆ˜

    # íƒ€ì„ì•„ì›ƒ ê´€ë ¨
    timeout_chunks = 0  # ìŒì„± ì‹œì‘ ì „ ëŒ€ê¸° ì‹œê°„ ì¹´ìš´í„°
    timeout_threshold = int(timeout * RATE / CHUNK)  # íƒ€ì„ì•„ì›ƒ í”„ë ˆì„ ìˆ˜ (10ì´ˆ = 500 í”„ë ˆì„)

    try:
        while True:
            # === ë§ˆì´í¬ì—ì„œ 20ms ë°ì´í„° ì½ê¸° ===
            data = stream.read(CHUNK, exception_on_overflow=False)

            # === VADë¡œ ìŒì„± ê°ì§€ ===
            # True = ìŒì„± ìˆìŒ, False = ì¹¨ë¬µ
            is_speech = vad.is_speech(data, RATE)

            if is_speech:
                # ìŒì„± ê°ì§€ë¨!
                if not speech_detected:
                    print("ğŸ—£ï¸  ë…¹ìŒ ì‹œì‘! (ë§ì”€í•˜ì„¸ìš”)")
                    speech_detected = True

                frames.append(data)  # ë°ì´í„° ì €ì¥
                silence_chunks = 0   # ì¹¨ë¬µ ì¹´ìš´í„° ë¦¬ì…‹

            else:
                # ì¹¨ë¬µ ê°ì§€ë¨
                if speech_detected:
                    # ìŒì„±ì´ ì‹œì‘ëœ ì´í›„ì˜ ì¹¨ë¬µ
                    frames.append(data)  # ì¹¨ë¬µë„ ì¼ë‹¨ ì €ì¥ (ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€ ìœ„í•´)
                    silence_chunks += 1  # ì¹¨ë¬µ ì¹´ìš´í„° ì¦ê°€

                    # ì¼ì • ì‹œê°„ ì´ìƒ ì¹¨ë¬µì´ë©´ ì¢…ë£Œ
                    if silence_chunks > silence_threshold:
                        print("âœ… ë…¹ìŒ ì™„ë£Œ! (ì¹¨ë¬µ ê°ì§€)")
                        break

                else:
                    # ìŒì„±ì´ ì•„ì§ ì‹œì‘ ì•ˆ ë¨ (ëŒ€ê¸° ì¤‘)
                    timeout_chunks += 1  # íƒ€ì„ì•„ì›ƒ ì¹´ìš´í„° ì¦ê°€

                    # íƒ€ì„ì•„ì›ƒ ì²´í¬
                    if timeout_chunks > timeout_threshold:
                        print(f"â±ï¸  íƒ€ì„ì•„ì›ƒ! ({timeout}ì´ˆ ë™ì•ˆ ìŒì„± ì—†ìŒ)")
                        stream.stop_stream()
                        stream.close()
                        p.terminate()
                        return None  # None ë¦¬í„´ = íƒ€ì„ì•„ì›ƒ

    except KeyboardInterrupt:
        print("\nâš ï¸  ë…¹ìŒ ì¤‘ë‹¨")

    finally:
        # === ì •ë¦¬ ===
        stream.stop_stream()
        stream.close()
        p.terminate()

    # === WAV íŒŒì¼ë¡œ ì €ì¥ ===
    if frames:
        wf = wave.open(filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
        wf.close()
        print(f"ğŸ’¾ íŒŒì¼ ì €ì¥: {filename}")
        return filename
    else:
        print("âŒ ë…¹ìŒëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤")
        return None


def speak(text, filename="temp_response.mp3"):
    """
    TTSë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥

    Args:
        text: ë§í•  í…ìŠ¤íŠ¸
        filename: ì„ì‹œ ìŒì„± íŒŒì¼ëª…
    """
    print(f"\nğŸ”Š ìŒì„± ì¶œë ¥: '{text}'")

    try:
        tts = gTTS(text=text, lang='ko')
        tts.save(filename)
        playsound(filename)
        os.remove(filename)
    except Exception as e:
        print(f"âŒ TTS ì—ëŸ¬: {e}")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("="*60)
    print("ì˜¤ë””ì˜¤ ëª¨ë“ˆ VAD í…ŒìŠ¤íŠ¸")
    print("="*60)

    # VAD ë…¹ìŒ í…ŒìŠ¤íŠ¸
    print("\në§ì”€í•˜ì„¸ìš”! (ë§ ëë‚˜ë©´ 1.5ì´ˆ í›„ ìë™ ì¢…ë£Œ)")
    audio_file = record_audio_vad()

    if audio_file:
        print(f"ë…¹ìŒ íŒŒì¼: {audio_file}")

        # TTS í…ŒìŠ¤íŠ¸
        speak("ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ì •ë¦¬
        if os.path.exists(audio_file):
            os.remove(audio_file)
    else:
        print("ë…¹ìŒ ì‹¤íŒ¨")
