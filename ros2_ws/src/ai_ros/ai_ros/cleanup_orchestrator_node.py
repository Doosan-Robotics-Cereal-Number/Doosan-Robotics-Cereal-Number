#!/usr/bin/env python3
"""
cleanup_orchestrator_node.py

RealSense ì•ˆì • ì´ë²¤íŠ¸ë¥¼ ë°›ì•„ ìµœì‹  ë””ë²„ê·¸ ì´ë¯¸ì§€ë¥¼ GPT Realtime Miniì— ì „ë‹¬í•˜ê³ 
ìŒì„± ìƒí˜¸ì‘ìš©ì„ íŠ¸ë¦¬ê±°í•˜ê¸° ìœ„í•œ ìŠ¤ìºí´ë”© ë…¸ë“œ.
"""

from __future__ import annotations

import asyncio
import base64
import binascii
import json
import os
import subprocess
import threading
import time
from collections import Counter
from typing import Optional, Dict, Any, List

import requests

import cv2
import numpy as np
import rclpy
import websockets
from cv_bridge import CvBridge, CvBridgeError
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String
from websockets.exceptions import InvalidStatusCode, InvalidMessage


class CleanupOrchestratorNode(Node):
    """Stable object ì´ë²¤íŠ¸ë¥¼ GPT Realtime ì›Œí¬í”Œë¡œìš°ë¡œ ì—°ê²°."""

    def __init__(self):
        super().__init__("cleanup_orchestrator")

        # Parameters
        self.declare_parameter("stable_event_topic", "/workspace_stable_object")
        self.declare_parameter("debug_image_topic", "/workspace_debug")
        self.declare_parameter("gpt_model", "gpt-5")
        self.declare_parameter("tts_model", "gpt-realtime-mini")
        self.declare_parameter("openai_api_key_env", "OPENAI_API_KEY")
        self.declare_parameter("audio_voice", "echo")
        self.declare_parameter("audio_speed", 1.0)
        self.declare_parameter("request_cooldown_sec", 30.0)
        self.declare_parameter("ask_prompt", "ë¬¼ê±´ì„ ì¹˜ì›Œ ë“œë¦´ê¹Œìš”?")
        self.declare_parameter("enable_requests", True)
        self.declare_parameter("auto_play_audio", True)
        self.declare_parameter("event_batch_delay_sec", 0.8)

        self.stable_event_topic = str(self.get_parameter("stable_event_topic").value)
        self.debug_image_topic = str(self.get_parameter("debug_image_topic").value)
        self.gpt_model = str(self.get_parameter("gpt_model").value)
        self.tts_model = str(self.get_parameter("tts_model").value)
        self.audio_voice = str(self.get_parameter("audio_voice").value)
        self.audio_speed = max(0.25, float(self.get_parameter("audio_speed").value))
        self.request_cooldown_sec = max(0.0, float(self.get_parameter("request_cooldown_sec").value))
        self.ask_prompt = str(self.get_parameter("ask_prompt").value)
        self.enable_requests = bool(self.get_parameter("enable_requests").value)
        self.auto_play_audio = bool(self.get_parameter("auto_play_audio").value)
        self.event_batch_delay_sec = max(0.0, float(self.get_parameter("event_batch_delay_sec").value))

        api_env = str(self.get_parameter("openai_api_key_env").value or "OPENAI_API_KEY")
        self.api_key = os.getenv(api_env)
        if not self.api_key:
            self.get_logger().warn(f"{api_env} is not set. GPT ìš”ì²­ì€ ê±´ë„ˆëœë‹ˆë‹¤.")

        self.http_session = requests.Session()
        self.bridge = CvBridge()
        self.latest_image: Optional[np.ndarray] = None
        self.latest_stamp: Optional[float] = None
        self.last_request_time = 0.0
        self.inflight_lock = threading.Lock()
        self.batch_lock = threading.Lock()
        self.pending_events: List[Dict[str, Any]] = []
        self.batch_timer: Optional[threading.Timer] = None

        self.debug_sub = self.create_subscription(Image, self.debug_image_topic, self._on_debug_image, 10)
        self.event_sub = self.create_subscription(String, self.stable_event_topic, self._on_stable_event, 10)

        self.get_logger().info("ğŸ§¹ Cleanup orchestrator ready.")

    # ------------------------------------------------------------------
    def _on_debug_image(self, msg: Image):
        try:
            frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
        except CvBridgeError as err:
            self.get_logger().warn(f"Failed to decode debug image: {err}")
            return
        self.latest_image = frame
        self.latest_stamp = self._stamp_to_seconds(msg.header.stamp) if msg.header else time.time()

    def _on_stable_event(self, msg: String):
        try:
            event = json.loads(msg.data)
        except json.JSONDecodeError as err:
            self.get_logger().warn(f"Stable event JSON parse error: {err}")
            return

        if self.latest_image is None:
            self.get_logger().warn("Stable event received but no debug image cached yet.")
            return

        if not self.enable_requests or not self.api_key:
            self.get_logger().info("Requests disabled or API key missing; logging only.")
            self._log_event(event)
            return

        with self.batch_lock:
            self.pending_events.append(event)
            if self.batch_timer:
                self.batch_timer.cancel()
            if self.event_batch_delay_sec <= 0.0:
                self.batch_timer = None
            else:
                self.batch_timer = threading.Timer(self.event_batch_delay_sec, self._process_pending_events)
                self.batch_timer.daemon = True
                self.batch_timer.start()

        if self.event_batch_delay_sec <= 0.0:
            self._process_pending_events()

    def _process_pending_events(self):
        with self.batch_lock:
            events = self.pending_events
            self.pending_events = []
            self.batch_timer = None

        if not events:
            return

        if self.latest_image is None:
            self.get_logger().warn("Batch ready but no debug image cached; skipping request.")
            return

        now = time.time()
        if now - self.last_request_time < self.request_cooldown_sec:
            self.get_logger().info("Skipping GPT request due to cooldown.")
            return

        frame = self.latest_image.copy()
        snapshot_bytes = self._encode_snapshot(frame)
        if snapshot_bytes is None:
            self.get_logger().warn("Failed to encode snapshot for GPT.")
            return

        self.last_request_time = now
        threading.Thread(
            target=self._handle_event_thread,
            args=(events, snapshot_bytes),
            daemon=True,
        ).start()

    # ------------------------------------------------------------------
    def _handle_event_thread(self, events: List[Dict[str, Any]], snapshot_bytes: bytes):
        with self.inflight_lock:
            self.get_logger().debug("Snapshot captured in memory (disk save skipped).")
            text = self._request_text_summary(events, snapshot_bytes)
            if not text:
                return
            tts_text = self._build_audio_prompt_from_text(text) or text
            audio = self._request_tts_audio(tts_text)
            self._handle_gpt_response({"text": text, "audio": audio, "tts_text": tts_text})

    def _request_text_summary(self, events: List[Dict[str, Any]], snapshot_bytes: bytes) -> Optional[str]:
        if not self.enable_requests:
            return None
        self.get_logger().info("ğŸ§  Requesting GPT text summary...")
        try:
            return self._request_text_summary_rest(events, snapshot_bytes)
        except Exception as err:
            self.get_logger().error(f"Text summary request failed: {err}")
            return None

    def _request_text_summary_rest(self, events: List[Dict[str, Any]], snapshot_bytes: bytes) -> Optional[str]:
        if not self.api_key:
            return None
        data_url = self._to_data_url(snapshot_bytes)
        if data_url is None:
            return None

        instructions = (
            "ë„ˆëŠ” ì‘ì—… ê³µê°„ ì •ë¦¬ ë„ìš°ë¯¸ë‹¤. ì†ë„ë³´ë‹¤ ì •í™•ë„ê°€ 100ë°° ë” ì¤‘ìš”í•˜ë‹ˆ ì‹ ì¤‘íˆ ì¶”ë¡ í•˜ë¼.\n"
            "ì´ë¯¸ì§€ ì† ê° IDë¥¼ ë‹¤ìŒ ë‹¨ì¼ í˜•ì‹ìœ¼ë¡œë§Œ ë³´ê³ í•˜ë˜, ì‹¤ì œ ë¬¼ì²´ëª…ì„ í™•ì‹¤íˆ í™•ì¸í•œ ë‹¤ìŒ ê¸°ì…í•˜ë¼:\n"
            "ID N: <ì •í™•í•œ í•œêµ­ì–´ ë¬¼ì²´ëª…>. ë¬¼ê±´ì„ ì¹˜ì›Œ ë“œë¦´ê¹Œìš”?\n"
            "<í•œêµ­ì–´ ë¬¼ì²´ëª…>ì€ ì»µ, í…€ë¸”ëŸ¬, ìš°ìœ ê³½, íœ´ì§€ ê°™ì€ ì§§ì€ ëª…ì‚¬ê°€ ë°”ëŒì§í•˜ì§€ë§Œ ì´ëŠ” ë‹¨ìˆœ ì˜ˆì‹œì— ë¶ˆê³¼í•˜ë©°, "
            "ì‹¤ì œ ê´€ì¸¡ëœ ë¬¼ì²´ì— ê°€ì¥ ì˜ ë§ëŠ” ëª…ì‚¬ë¥¼ ììœ ë¡­ê²Œ ê³¨ë¼ì•¼ í•œë‹¤. ì• ë§¤í•˜ë©´ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ëª…ì‚¬ë¥¼ 1ê°œë§Œ ì„ íƒí•˜ë¼. "
            "ì—¬ëŸ¬ IDê°€ ìˆìœ¼ë©´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ê³ , ì´ í˜•ì‹ ì™¸ì˜ ë¬¸ì¥/ì„¤ëª…/ì ‘ì†ì‚¬ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆë¼."
        )

        user_prompt = self._build_user_prompt(events)
        payload = {
            "model": self.gpt_model,
            "input": [
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": f"{instructions}\n{user_prompt}"},
                        {"type": "input_image", "image_url": data_url, "detail": "high"},
                    ],
                }
            ],
        }
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        try:
            response = self.http_session.post(
                "https://api.openai.com/v1/responses",
                headers=headers,
                json=payload,
                timeout=60,
            )
        except requests.RequestException as err:
            self.get_logger().error(f"Responses request failed: {err}")
            return None

        if response.status_code != 200:
            self.get_logger().error(f"Responses API error {response.status_code}: {response.text}")
            return None

        try:
            data = response.json()
        except ValueError as err:
            self.get_logger().error(f"Failed to parse Responses JSON: {err}")
            return None

        result = self._extract_text_from_response(data)
        if result:
            self.get_logger().info("ğŸ“ GPT text summary received.")
        else:
            self.get_logger().warn("Responses API returned no text output.")
        return result

    def _request_tts_audio(self, text: str) -> Optional[bytes]:
        if not text or not self.enable_requests:
            return None
        self.get_logger().info("ğŸ™ï¸ Requesting GPT TTS audio...")
        try:
            return asyncio.run(self._tts_async(text))
        except RuntimeError as err:
            if "asyncio.run()" in str(err):
                loop = asyncio.new_event_loop()
                try:
                    asyncio.set_event_loop(loop)
                    return loop.run_until_complete(self._tts_async(text))
                finally:
                    asyncio.set_event_loop(None)
                    loop.close()
            self.get_logger().error(f"TTS request failed: {err}")
            return None
        except Exception as err:
            self.get_logger().error(f"TTS exception: {err}")
            return None

    async def _tts_async(self, text: str) -> Optional[bytes]:
        self.get_logger().info(f"ğŸ™ï¸ Starting TTS with voice={self.audio_voice}, speed={self.audio_speed}")

        url = f"wss://api.openai.com/v1/realtime?model={self.tts_model or self.gpt_model}"
        headers = [
            ("Authorization", f"Bearer {self.api_key}"),
            ("OpenAI-Beta", "realtime=v1"),
        ]
        try:
            ws = await websockets.connect(url, extra_headers=headers, ping_interval=20)
        except TypeError as err:
            if "extra_headers" in str(err):
                ws = await websockets.connect(url, additional_headers=headers, ping_interval=20)
            else:
                raise
        except Exception as err:
            self.get_logger().error(f"TTS websocket open failed: {err}")
            return None

        self.get_logger().debug("Realtime TTS session opened.")

        audio_chunks: List[str] = []
        seen_events: Counter[str] = Counter()
        misc_log_budget = 3
        try:
            async with ws:
                await ws.send(
                    json.dumps(
                        {
                            "type": "session.update",
                            "session": {
                                "modalities": ["audio", "text"],
                                "voice": self.audio_voice,
                                "instructions": "ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ê¸€ì í•˜ë‚˜ë„ ë¹ ëœ¨ë¦¬ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì½ì–´ë¼. "
                                "ê°íƒ„ì‚¬ë‚˜ ì–´ë¯¸ë¥¼ ìƒˆë¡œ ë§Œë“¤ì§€ ë§ê³  ì „ë‹¬ëœ ë¬¸ì¥ë§Œ ì •í™•í•˜ê²Œ ë‚­ë…í•˜ë¼.",
                                "temperature": 0.6,
                            },
                        }
                    )
                )
                safe_text = text.replace('"', "'")
                instructions = (
                    "ë”°ì˜´í‘œ ì•ˆ ë¬¸ì¥ì„ í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ì½ì–´ë¼. "
                    "ì¶”ê°€ ë©˜íŠ¸ë‚˜ ê°íƒ„ì‚¬ëŠ” ì ˆëŒ€ í•˜ì§€ ë§ˆë¼. "
                    f'ë¬¸ì¥: "{safe_text}"'
                )
                await ws.send(
                    json.dumps(
                        {
                            "type": "response.create",
                            "response": {
                                "modalities": ["audio", "text"],
                                "instructions": instructions,
                                "temperature": 0.6,
                            },
                        }
                    )
                )
                async for raw in ws:
                    evt = json.loads(raw)
                    evt_type = evt.get("type")
                    seen_events[evt_type] += 1
                    if evt_type in ("response.output_audio.delta", "response.audio.delta"):
                        delta = evt.get("delta")
                        if isinstance(delta, dict):
                            chunk = delta.get("audio")
                        else:
                            chunk = delta
                        if chunk:
                            audio_chunks.append(chunk)
                    elif evt_type in ("response.output_text.delta", "response.text.delta", "response.audio_transcript.delta"):
                        if misc_log_budget > 0:
                            self.get_logger().debug(f"TTS text delta (ignored): {evt.get('delta')}")
                            misc_log_budget -= 1
                    elif evt_type in ("response.output_audio.done", "response.audio.done", "response.completed", "response.done"):
                        break
                    elif evt_type == "response.error":
                        self.get_logger().error(f"TTS realtime error: {evt}")
                        break
                    elif misc_log_budget > 0:
                        self.get_logger().debug(f"TTS event ({evt_type}): {evt}")
                        misc_log_budget -= 1
        except asyncio.TimeoutError:
            self.get_logger().error("Realtime TTS session timed out.")
            return None
        except (InvalidStatusCode, InvalidMessage) as err:
            self.get_logger().error(f"TTS websocket error: {err}")
            return None
        except Exception as err:
            self.get_logger().error(f"TTS session failed: {err}")
            return None

        if not audio_chunks:
            counts = ", ".join(f"{k}={v}" for k, v in seen_events.items())
            self.get_logger().warn(
                "Realtime TTS produced no audio chunks. "
                + (f"Events seen: {counts}" if counts else "No events received after response request.")
            )
            return None

        audio = self._merge_audio_chunks(audio_chunks)
        if audio:
            self.get_logger().info("ğŸ”‰ GPT audio received.")
        return audio

    def _handle_gpt_response(self, data: Dict[str, Any]):
        text_response = data.get("text", "") if data else ""
        audio_bytes = data.get("audio") if data else None
        tts_text = data.get("tts_text") or text_response
        if text_response:
            self.get_logger().info("GPT text summary:\n" + text_response)
        if audio_bytes:
            self.get_logger().info("Received audio response.")
            if self.auto_play_audio:
                spoken = (tts_text or "").replace("\n", " ").strip()
                if spoken:
                    self.get_logger().info(f"ğŸ”Š Speaking text: {spoken}")
                self._play_audio_stream(audio_bytes)

    # ------------------------------------------------------------------
    def _build_user_prompt(self, events: List[Dict[str, Any]]) -> str:
        lines = [
            "ë‹¤ìŒ ì•ˆì • ê°ì²´ë“¤ì´ ë™ì‹œì— ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ê° IDì— ëŒ€í•´ ì‹¤ì œ ë¬¼ì²´ëª…ì„ ë³´ê³ í•˜ì„¸ìš”.",
            "ì´ë¯¸ì§€ì˜ ID í‘œê¸°ë¥¼ í™•ì¸í•˜ê³  ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”: 'ID N: ì‹¤ì œ ë¬¼ì²´ëª…. ë¬¼ê±´ì„ ì¹˜ì›Œ ë“œë¦´ê¹Œìš”?'",
            "ë‹¨, 'ë¬¼ì²´ëª…'ì´ë¼ëŠ” ë‹¨ì–´ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ê³  ì»µ/ë³‘/íœ´ì§€/ë°•ìŠ¤ ê°™ì€ ì‹¤ì œ ëª…ì‚¬ë¥¼ ë„£ìœ¼ì„¸ìš”.",
            "ì˜ˆì‹œëŠ” ì°¸ê³ ìš©ì¼ ë¿ì´ë©°, ì‹¤ì œë¡œ ë³´ì´ëŠ” ë¬¼ì²´ì— ê°€ì¥ ì•Œë§ì€ í•œêµ­ì–´ ëª…ì‚¬ë¥¼ ììœ ë¡­ê²Œ ì„ íƒí•˜ì„¸ìš”.",
        ]
        for event in events:
            obj_id = event.get("id", "?")
            pos = event.get("position_mm")
            px = event.get("pixel")
            desc = f"- ID {obj_id}"
            if pos is not None:
                desc += f": ìœ„ì¹˜ {pos} mm"
            if px:
                desc += f", í”½ì…€ {px}"
            lines.append(desc)
        lines.append(self.ask_prompt)
        return "\n".join(lines)

    def _encode_snapshot(self, frame: np.ndarray) -> Optional[bytes]:
        success, buffer = cv2.imencode(".jpg", frame, [int(cv2.IMWRITE_JPEG_QUALITY), 92])
        if not success:
            return None
        return buffer.tobytes()

    def _to_data_url(self, snapshot_bytes: bytes) -> Optional[str]:
        if not snapshot_bytes:
            return None
        b64 = base64.b64encode(snapshot_bytes).decode("ascii")
        return "data:image/jpeg;base64," + b64

    @staticmethod
    def _extract_text_from_response(payload: Dict[str, Any]) -> Optional[str]:
        outputs = payload.get("output") or []
        chunks: List[str] = []
        for item in outputs:
            if not isinstance(item, dict):
                continue
            if item.get("type") != "message":
                continue
            for block in item.get("content", []):
                if not isinstance(block, dict):
                    continue
                if block.get("type") == "output_text":
                    chunks.append(str(block.get("text", "")))
        text = "".join(chunks).strip()
        if text:
            return text
        raw_text = payload.get("output_text")
        if isinstance(raw_text, list):
            merged = "".join(str(part) for part in raw_text).strip()
            return merged or None
        if isinstance(raw_text, str):
            stripped = raw_text.strip()
            return stripped or None
        return None

    def _build_audio_prompt_from_text(self, text: str) -> Optional[str]:
        names = self._extract_item_names(text)
        if not names:
            return None
        if len(names) == 1:
            target = names[0] + self._object_particle(names[0])
        elif len(names) == 2:
            connector = self._conjunction_particle(names[0])
            target = f"{names[0]}{connector} {names[1]}{self._object_particle(names[1])}"
        else:
            prefix = ", ".join(names[:-1])
            target = f"{prefix}, ê·¸ë¦¬ê³  {names[-1]}{self._object_particle(names[-1])}"
        return f"{target} ì¹˜ì›Œ ë“œë¦´ê¹Œìš”?"

    @staticmethod
    def _extract_item_names(text: str) -> List[str]:
        names: List[str] = []
        for line in text.splitlines():
            line = line.strip()
            if not line or not line.lower().startswith("id"):
                continue
            parts = line.split(":", 1)
            if len(parts) != 2:
                continue
            rest = parts[1].strip()
            if not rest:
                continue
            name = rest.split(".", 1)[0].strip()
            if name and not name.lower().startswith("ë¬¼ì²´ëª…"):
                names.append(name)
        return names

    @staticmethod
    def _object_particle(word: str) -> str:
        return "ì„" if CleanupOrchestratorNode._has_final_consonant(word) else "ë¥¼"

    @staticmethod
    def _conjunction_particle(word: str) -> str:
        return "ê³¼" if CleanupOrchestratorNode._has_final_consonant(word) else "ì™€"

    @staticmethod
    def _has_final_consonant(word: str) -> bool:
        if not word:
            return False
        ch = word[-1]
        code = ord(ch)
        if 0xAC00 <= code <= 0xD7A3:
            return (code - 0xAC00) % 28 != 0
        return False

    def _merge_audio_chunks(self, chunks: List[str]) -> Optional[bytes]:
        if not chunks:
            return None
        decoded: List[bytes] = []
        for idx, chunk in enumerate(chunks):
            if not chunk:
                continue
            if not isinstance(chunk, str):
                self.get_logger().warn(
                    f"Skipping audio chunk #{idx} because it is type {type(chunk).__name__}, expected str."
                )
                continue
            try:
                decoded.append(base64.b64decode(chunk))
            except (ValueError, binascii.Error, TypeError) as err:
                self.get_logger().warn(f"Failed to decode audio chunk #{idx}: {err}")
        if not decoded:
            return None
        return b"".join(decoded)

    def _play_audio_stream(self, audio_bytes: bytes):
        try:
            proc = subprocess.Popen(
                ["ffplay", "-autoexit", "-nodisp", "-loglevel", "error", "-f", "s16le", "-ar", "16000", "-ac", "1", "-i", "pipe:0"],
                stdin=subprocess.PIPE,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
            )
        except FileNotFoundError:
            self.get_logger().warn("aplay not found; skipping audio playback.")
            return
        except Exception as err:
            self.get_logger().warn(f"Failed to start audio playback: {err}")
            return

        try:
            stderr_output = proc.communicate(input=audio_bytes, timeout=30)[1] or b""
        except subprocess.TimeoutExpired:
            proc.kill()
            self.get_logger().warn("Audio playback timed out; ffplay was terminated.")
            return
        except Exception as err:
            proc.kill()
            self.get_logger().warn(f"Failed to stream audio: {err}")
            return

        if proc.returncode != 0:
            message = stderr_output.decode("utf-8", errors="ignore").strip()
            detail = f": {message}" if message else ""
            self.get_logger().warn(f"ffplay exited with code {proc.returncode}{detail}")
        elif stderr_output:
            self.get_logger().debug(stderr_output.decode("utf-8", errors="ignore").strip())

    @staticmethod
    def _stamp_to_seconds(stamp) -> float:
        return stamp.sec + stamp.nanosec * 1e-9

    def _log_event(self, event: Dict[str, Any]):
        self.get_logger().info(f"[Dry-run] Stable event: {json.dumps(event, ensure_ascii=False)}")

    def destroy_node(self):
        try:
            self.http_session.close()
        finally:
            super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    node = CleanupOrchestratorNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == "__main__":
    main()
