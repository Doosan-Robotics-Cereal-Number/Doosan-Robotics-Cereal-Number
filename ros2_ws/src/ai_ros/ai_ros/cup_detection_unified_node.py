#!/usr/bin/env python3
"""
cup_detection_unified_node.py (Fixed)
í†µí•© ì»µ ê°ì§€ ë…¸ë“œ - êµ¬ì—­ë³„ ë…ë¦½ ê°ì§€

ìˆ˜ì •ì‚¬í•­:
- personal_cup_st: call_coordsë¡œë§Œ ì œì–´
- pickup_st1/st2: check_cupìœ¼ë¡œë§Œ ì œì–´
- ìƒí˜¸ ê°„ì„­ ì—†ìŒ
"""

import cv2
import rclpy
from rclpy.node import Node
import pyrealsense2 as rs
import numpy as np
from collections import deque
from typing import Dict, Optional

from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Float32MultiArray, Bool
from cv_bridge import CvBridge, CvBridgeError
import message_filters
from ultralytics import YOLO


def point_in_rect(x: float, y: float, rect: Dict[str, float]) -> bool:
    """ì ì´ ì‚¬ê°í˜• ì•ˆì— ìˆëŠ”ì§€ í™•ì¸"""
    return (rect['xmin'] <= x <= rect['xmax']) and (rect['ymin'] <= y <= rect['ymax'])


class CupDetectionUnifiedNode(Node):
    """
    í†µí•© ì»µ ê°ì§€ ë…¸ë“œ (êµ¬ì—­ë³„ ë…ë¦½ ì œì–´)
    """
    
    def __init__(self):
        super().__init__("cup_detection_unified_node")
        
        # =====================================================
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        # =====================================================
        self.declare_parameter('model', 'yolov8m.pt')
        self.declare_parameter('conf', 0.04)
        self.declare_parameter('imgsz', 1280)
        self.declare_parameter('device', 'cpu')
        self.declare_parameter('class_label', 'cup')
        
        self.declare_parameter('detect_delay_sec', 0.8)
        self.declare_parameter('window_size', 20)
        self.declare_parameter('stable_radius', 0.01)
        
        self.declare_parameter('color_topic', '/camera/camera/color/image_raw')
        self.declare_parameter('depth_topic', '/camera/camera/aligned_depth_to_color/image_raw')
        self.declare_parameter('info_topic', '/camera/camera/aligned_depth_to_color/camera_info')
        
        self.declare_parameter('visualize', True)
        self.declare_parameter('min_box_area', 200)
        
        # íŒŒë¼ë¯¸í„° ë¡œë“œ
        self.model_path = self.get_parameter('model').value
        self.conf = float(self.get_parameter('conf').value)
        self.imgsz = int(self.get_parameter('imgsz').value)
        self.device = str(self.get_parameter('device').value)
        self.class_label = str(self.get_parameter('class_label').value)
        
        self.detect_delay_sec = float(self.get_parameter('detect_delay_sec').value)
        self.window_size = int(self.get_parameter('window_size').value)
        self.stable_radius = float(self.get_parameter('stable_radius').value)
        
        self.color_topic = str(self.get_parameter('color_topic').value)
        self.depth_topic = str(self.get_parameter('depth_topic').value)
        self.info_topic = str(self.get_parameter('info_topic').value)
        
        self.visualize = bool(self.get_parameter('visualize').value)
        self.min_box_area = int(self.get_parameter('min_box_area').value)

        # =====================================================
        # ë‚´ë¶€ ë³€ìˆ˜
        # =====================================================
        self.bridge = CvBridge()
        self.intrinsics: Optional[rs.intrinsics] = None
        self.latest_cv_color = None
        self.latest_cv_depth_mm = None
        
        # ğŸ”¥ êµ¬ì—­ë³„ ë…ë¦½ í”Œë˜ê·¸
        self._detect_personal = False  # call_coordsë¡œ ì œì–´
        self._detect_pickup = False    # check_cupìœ¼ë¡œ ì œì–´
        self._publish_coords_active = False
        
        # ì•ˆì •í™” ë²„í¼
        self.detect_buf = deque(maxlen=self.window_size)
        self.first_detect_time = None
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        self.model = YOLO(self.model_path)
        self.get_logger().info(f"âœ… YOLO model loaded: {self.model_path}")
        
        # =====================================================
        # êµ¬ì—­ ì •ì˜
        # =====================================================
        self.zones: Dict[str, Dict[str, float]] = {
            'personal_cup_st': {
                'xmin': 0.400, 'xmax': 0.625,
                'ymin': -0.344, 'ymax': -0.166,
            },
            'pickup_st1': {
                'xmin': 0.393, 'xmax': 0.520,
                'ymin': -0.010, 'ymax': 0.152,
            },
            'pickup_st2': {
                'xmin': 0.520, 'xmax': 0.640,
                'ymin': -0.010, 'ymax': 0.152,
            },
        }
        
        # =====================================================
        # ì¹´ë©”ë¼ í† í”½ êµ¬ë…
        # =====================================================
        self.color_sub = message_filters.Subscriber(self, Image, self.color_topic)
        self.depth_sub = message_filters.Subscriber(self, Image, self.depth_topic)
        self.info_sub = message_filters.Subscriber(self, CameraInfo, self.info_topic)
        
        self.ts = message_filters.ApproximateTimeSynchronizer(
            [self.color_sub, self.depth_sub, self.info_sub],
            queue_size=10,
            slop=0.1
        )
        self.ts.registerCallback(self._camera_callback)
        
        # =====================================================
        # ì œì–´ í† í”½ êµ¬ë…
        # =====================================================
        self.create_subscription(Bool, '/check_cup', self._on_check_cup, 10)
        self.create_subscription(Bool, '/check_cup_done', self._on_check_cup_done, 10)
        self.create_subscription(Bool, '/call_cup_stable_coordinates', self._on_call_coords, 10)
        self.create_subscription(Bool, '/arrive_cup_stable_coordinates', self._on_arrive_coords, 10)
        
        # =====================================================
        # ë°œí–‰ì
        # =====================================================
        self.pub_personal = self.create_publisher(Bool, '/cup_detections/personal_cup_st', 10)
        self.pub_pick1 = self.create_publisher(Bool, '/cup_detections/pickup_st1', 10)
        self.pub_pick2 = self.create_publisher(Bool, '/cup_detections/pickup_st2', 10)
        self.cup_coord_pub = self.create_publisher(Float32MultiArray, '/cup_stable_coordinates', 10)
        
        # =====================================================
        # ì‹œì‘ ë©”ì‹œì§€
        # =====================================================
        self.get_logger().info("=" * 60)
        self.get_logger().info("âœ… Cup Detection Unified Node Started (Fixed)")
        self.get_logger().info(f"   YOLO: {self.model_path}")
        self.get_logger().info("   Control:")
        self.get_logger().info("     - personal_cup_st: call_coords")
        self.get_logger().info("     - pickup_st1/st2: check_cup")
        self.get_logger().info("=" * 60)
    
    # =====================================================
    # ì œì–´ ì½œë°±
    # =====================================================
    def _on_check_cup(self, msg: Bool):
        """check_cup ì‹ í˜¸ â†’ pickup êµ¬ì—­ ê°ì§€ ì œì–´"""
        if msg.data and not self._detect_pickup:
            self._detect_pickup = True
            self.get_logger().info("ğŸŸ¢ Pickup detection STARTED")
        elif not msg.data and self._detect_pickup:
            self._detect_pickup = False
            self._publish_pickup_false()
            self.get_logger().info("ğŸ”´ Pickup detection STOPPED")
    
    def _on_check_cup_done(self, msg: Bool):
        """check_cup_done ì‹ í˜¸ â†’ pickup êµ¬ì—­ ê°ì§€ ì¤‘ì§€"""
        if msg.data and self._detect_pickup:
            self._detect_pickup = False
            self._publish_pickup_false()
            self.get_logger().info("ğŸ”´ Pickup detection STOPPED (done)")
    
    def _on_call_coords(self, msg: Bool):
        """call_cup_stable_coordinates ì‹ í˜¸ â†’ ê°œì¸ì»µ êµ¬ì—­ ê°ì§€ + ì¢Œí‘œ ë°œí–‰"""
        if msg.data and not self._detect_personal:
            self._detect_personal = True
            self._publish_coords_active = True
            self._reset_buffers()
            self.get_logger().info("ğŸŸ¢ Personal cup detection + coords STARTED")
        elif not msg.data and self._detect_personal:
            self._detect_personal = False
            self._publish_coords_active = False
            self._reset_buffers()
            self.pub_personal.publish(Bool(data=False))
            self.get_logger().info("ğŸ”´ Personal cup detection + coords STOPPED")
    
    def _on_arrive_coords(self, msg: Bool):
        """arrive_cup_stable_coordinates ì‹ í˜¸ â†’ ê°œì¸ì»µ êµ¬ì—­ ê°ì§€ ì¤‘ì§€"""
        if msg.data and self._detect_personal:
            self._detect_personal = False
            self._publish_coords_active = False
            self._reset_buffers()
            self.pub_personal.publish(Bool(data=False))
            self.get_logger().info("ğŸ”´ Personal cup detection + coords STOPPED (arrived)")
    
    def _publish_pickup_false(self):
        """pickup êµ¬ì—­ í”Œë˜ê·¸ë§Œ Falseë¡œ ë°œí–‰"""
        self.pub_pick1.publish(Bool(data=False))
        self.pub_pick2.publish(Bool(data=False))
    
    def _reset_buffers(self):
        """ì¢Œí‘œ ì•ˆì •í™” ë²„í¼ ì´ˆê¸°í™”"""
        self.detect_buf.clear()
        self.first_detect_time = None
    
    # =====================================================
    # ìœ í‹¸ë¦¬í‹°
    # =====================================================
    def _which_zone(self, x: float, y: float) -> Optional[str]:
        """ì¹´ë©”ë¼ ì¢Œí‘œê³„ (x,y)ê°€ ì–´ëŠ êµ¬ì—­ì— ì†í•˜ëŠ”ì§€ ë°˜í™˜"""
        for name, rect in self.zones.items():
            if point_in_rect(x, y, rect):
                return name
        return None

    
    def _transform_to_robot_coords(self, X: float, Y: float, Z: float) -> list:
        """ì¹´ë©”ë¼ ì¢Œí‘œê³„ â†’ ë¡œë´‡ ì¢Œí‘œê³„ ë³€í™˜"""
        x_mm = Y * 1000
        y_mm = X * 1000
        z_mm = Z * 1000
        
        final_x = 777 + x_mm - 249 + 262
        final_y = y_mm -265
        final_z = 970 - z_mm - 200
        
        if final_z <= 55:
            final_z = 55
        
        return [float(final_x), float(final_y), float(final_z)]
    
    # =====================================================
    # ë©”ì¸ ì¹´ë©”ë¼ ì½œë°±
    # =====================================================
    def _camera_callback(self, color_msg: Image, depth_msg: Image, info_msg: CameraInfo):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì²˜ë¦¬ (êµ¬ì—­ë³„ ë…ë¦½ ê°ì§€)"""
        try:
            self.latest_cv_color = self.bridge.imgmsg_to_cv2(color_msg, "bgr8")
            self.latest_cv_depth_mm = self.bridge.imgmsg_to_cv2(depth_msg, "16UC1")
        except CvBridgeError as e:
            self.get_logger().error(f"CV Bridge error: {e}")
            return
        
        # Intrinsics ì„¤ì •
        if self.intrinsics is None:
            self.intrinsics = rs.intrinsics()
            self.intrinsics.width = info_msg.width
            self.intrinsics.height = info_msg.height
            self.intrinsics.ppx = info_msg.k[2]
            self.intrinsics.ppy = info_msg.k[5]
            self.intrinsics.fx = info_msg.k[0]
            self.intrinsics.fy = info_msg.k[4]
            
            if info_msg.distortion_model in ['plumb_bob', 'rational_polynomial']:
                self.intrinsics.model = rs.distortion.brown_conrady
            else:
                self.intrinsics.model = rs.distortion.none
            
            self.intrinsics.coeffs = list(info_msg.d)
            self.get_logger().info("ğŸ“· Camera intrinsics configured")
        
        # -------------------------
        # ğŸ”¥ YOLO ê°ì§€ (êµ¬ì—­ë³„ ë…ë¦½)
        # -------------------------
        detected_personal = False
        detected_pick1 = False
        detected_pick2 = False
        personal_cup_coords = None
        
        # ì–´ëŠ í•œ êµ¬ì—­ì´ë¼ë„ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ YOLO ì‹¤í–‰
        if self._detect_personal or self._detect_pickup:
            results = self.model.predict(
                source=self.latest_cv_color,
                imgsz=self.imgsz,
                conf=self.conf,
                device=self.device,
                verbose=False
            )[0]
            
            boxes = getattr(results, 'boxes', None)
            names = self.model.names
            
            if boxes is not None and len(boxes) > 0:
                xyxy = boxes.xyxy.cpu().numpy().astype(int)
                cls = boxes.cls.cpu().numpy().astype(int)
                
                for i in range(len(xyxy)):
                    cls_id = int(cls[i])
                    label = names.get(cls_id, str(cls_id))
                    
                    if label != self.class_label:
                        continue
                    
                    x1, y1, x2, y2 = xyxy[i]
                    
                    if (x2 - x1) * (y2 - y1) < self.min_box_area:
                        continue
                    
                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                    
                    if cy < 0 or cy >= self.latest_cv_depth_mm.shape[0] or \
                       cx < 0 or cx >= self.latest_cv_depth_mm.shape[1]:
                        continue
                    
                    d_mm = int(self.latest_cv_depth_mm[cy, cx])
                    if d_mm == 0:
                        continue
                    
                    depth_m = d_mm / 1000.0
                    
                    X, Y, Z = rs.rs2_deproject_pixel_to_point(
                        self.intrinsics, [cx, cy], depth_m
                    )
                    
                    zone = self._which_zone(float(X), float(Y))
                    if zone is None:
                        continue
                    
                    # ğŸ”¥ êµ¬ì—­ë³„ í”Œë˜ê·¸ ì²´í¬
                    if zone == 'personal_cup_st' and self._detect_personal:
                        detected_personal = True
                        personal_cup_coords = (float(X), float(Y), float(Z))
                    
                    elif zone == 'pickup_st1' and self._detect_pickup:
                        detected_pick1 = True
                    
                    elif zone == 'pickup_st2' and self._detect_pickup:
                        detected_pick2 = True
                    
                    # ì‹œê°í™”
                    if self.visualize:
                        cv2.rectangle(self.latest_cv_color, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        cv2.circle(self.latest_cv_color, (cx, cy), 4, (0, 0, 255), -1)
                        cv2.putText(
                            self.latest_cv_color,
                            f"{zone} {depth_m:.2f}m",
                            (x1, max(0, y1 - 8)),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.6,
                            (255, 255, 0),
                            2
                        )
            
            # ğŸ”¥ êµ¬ì—­ë³„ Bool í† í”½ ë°œí–‰
            if self._detect_personal:
                self.pub_personal.publish(Bool(data=detected_personal))
            
            if self._detect_pickup:
                self.pub_pick1.publish(Bool(data=detected_pick1))
                self.pub_pick2.publish(Bool(data=detected_pick2))
            
            # ë¡œê·¸
            detected_zones = []
            if detected_personal and self._detect_personal:
                detected_zones.append("personal_cup_st")
            if detected_pick1 and self._detect_pickup:
                detected_zones.append("pickup_st1")
            if detected_pick2 and self._detect_pickup:
                detected_zones.append("pickup_st2")
            
            if detected_zones:
                self.get_logger().info(f"ğŸ” Detected: {', '.join(detected_zones)}")
        
        # -------------------------
        # ê°œì¸ì»µ ì¢Œí‘œ ì•ˆì •í™”
        # -------------------------
        if self._publish_coords_active and personal_cup_coords is not None:
            self._process_personal_cup_coords(personal_cup_coords)
        
        # -------------------------
        # ì‹œê°í™”
        # -------------------------
        if self.visualize and self.latest_cv_color is not None:
            display = self.latest_cv_color.copy()
            
            # ìƒíƒœ í‘œì‹œ
            personal_status = "ACTIVE" if self._detect_personal else "IDLE"
            personal_color = (0, 255, 0) if self._detect_personal else (128, 128, 128)
            cv2.putText(display, f"Personal: {personal_status}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, personal_color, 2)
            
            pickup_status = "ACTIVE" if self._detect_pickup else "IDLE"
            pickup_color = (0, 255, 0) if self._detect_pickup else (128, 128, 128)
            cv2.putText(display, f"Pickup: {pickup_status}", (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, pickup_color, 2)
            
            buf_text = f"Buffer: {len(self.detect_buf)}/{self.window_size}"
            cv2.putText(display, buf_text, (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            cv2.imshow("Cup Detection Unified", display)
            cv2.waitKey(1)
    
    # =====================================================
    # ê°œì¸ì»µ ì¢Œí‘œ ì•ˆì •í™” ë° ë°œí–‰
    # =====================================================
    def _process_personal_cup_coords(self, coords: tuple):
        """ê°œì¸ì»µ ì¢Œí‘œë¥¼ ì•ˆì •í™”í•˜ê³  ë°œí–‰"""
        X, Y, Z = coords
        now = self.get_clock().now()
        
        if self.first_detect_time is None:
            self.first_detect_time = now
            self.detect_buf.clear()
            self.detect_buf.append((X, Y, Z))
            self.get_logger().info("ğŸ” Personal cup detected - collecting samples...")
            return
        
        if len(self.detect_buf) > 0:
            lastX, lastY, lastZ = self.detect_buf[-1]
            if (abs(X - lastX) > 0.05) or (abs(Y - lastY) > 0.05) or (abs(Z - lastZ) > 0.05):
                self.get_logger().warn("âš ï¸  Large jump detected - resetting buffer")
                self.first_detect_time = now
                self.detect_buf.clear()
        
        self.detect_buf.append((X, Y, Z))
        
        elapsed = (now - self.first_detect_time).nanoseconds / 1e9
        if elapsed < self.detect_delay_sec:
            return
        
        xs = [p[0] for p in self.detect_buf]
        ys = [p[1] for p in self.detect_buf]
        zs = [p[2] for p in self.detect_buf]
        
        Xavg = sum(xs) / len(xs)
        Yavg = sum(ys) / len(ys)
        Zavg = sum(zs) / len(zs)
        
        if any(abs(px - Xavg) > self.stable_radius for px in xs) or \
           any(abs(py - Yavg) > self.stable_radius for py in ys) or \
           any(abs(pz - Zavg) > self.stable_radius for pz in zs):
            self.get_logger().debug("   Stabilizing...")
            self.first_detect_time = now
            return
        
        self.get_logger().info(f"âœ… Position stabilized ({len(self.detect_buf)} samples)")
        self.get_logger().info(f"   Camera: X={Xavg:.3f}, Y={Yavg:.3f}, Z={Zavg:.3f}")
        
        robot_coords = self._transform_to_robot_coords(Xavg, Yavg, Zavg)
        
        self.get_logger().info(f"   Robot: X={robot_coords[0]:.1f}, Y={robot_coords[1]:.1f}, Z={robot_coords[2]:.1f}")
        
        coord_msg = Float32MultiArray()
        coord_msg.data = robot_coords
        self.cup_coord_pub.publish(coord_msg)
        
        self.get_logger().info("ğŸ“¢ Cup coordinates published!")
        
        self.detect_buf.clear()
        self.first_detect_time = None
    
    # =====================================================
    # ë§ˆìš°ìŠ¤ í´ë¦­ ì½œë°±
    # =====================================================
    def mouse_callback(self, event, u, v, flags, param):
        """ë§ˆìš°ìŠ¤ í´ë¦­ìœ¼ë¡œ ìˆ˜ë™ ì¢Œí‘œ ê³„ì‚°"""
        if event != cv2.EVENT_LBUTTONDOWN:
            return

        self.get_logger().info(f"[PIXEL] click at ({u}, {v})")

        if self.latest_cv_depth_mm is None or self.intrinsics is None:
            self.get_logger().warn("No depth data available; only pixel coordinates recorded.")
            return

        try:
            depth_mm = self.latest_cv_depth_mm[v, u]
        except IndexError:
            self.get_logger().warn("Clicked pixel is outside image bounds.")
            return

        if depth_mm == 0:
            self.get_logger().warn("Depth value is 0 at the clicked pixel; cannot compute 3D coordinates.")
            return
        
        depth_m = float(depth_mm) / 1000.0
        point_3d = rs.rs2_deproject_pixel_to_point(self.intrinsics, [u, v], depth_m)
        
        X, Y, Z = float(point_3d[0]), float(point_3d[1]), float(point_3d[2])
        robot_coords = self._transform_to_robot_coords(X, Y, Z)
        
        self.get_logger().info("=" * 60)
        self.get_logger().info(f"ğŸ–±ï¸  Manual click at pixel ({u}, {v})")
        self.get_logger().info(f"   Camera: X={X:.3f}, Y={Y:.3f}, Z={Z:.3f}")
        self.get_logger().info(f"   Robot: X={robot_coords[0]:.1f}, Y={robot_coords[1]:.1f}, Z={robot_coords[2]:.1f}")
        self.get_logger().info("=" * 60)
        
        coord_msg = Float32MultiArray()
        coord_msg.data = robot_coords
        self.cup_coord_pub.publish(coord_msg)


def main(args=None):
    rclpy.init(args=args)
    
    node = CupDetectionUnifiedNode()
    
    if node.visualize:
        cv2.namedWindow("Cup Detection Unified")
        cv2.setMouseCallback("Cup Detection Unified", node.mouse_callback)
    
    print("=" * 60)
    print("Cup Detection Unified Node (Fixed)")
    print("")
    print("ğŸ® Control:")
    print("  - check_cup â†’ pickup_st1/st2 detection")
    print("  - call_coords â†’ personal_cup_st detection + coords")
    print("")
    print("ğŸ“¤ Publishing:")
    print("  - /cup_detections/personal_cup_st")
    print("  - /cup_detections/pickup_st1")
    print("  - /cup_detections/pickup_st2")
    print("  - /cup_stable_coordinates")
    print("=" * 60)
    
    try:
        while rclpy.ok():
            rclpy.spin_once(node, timeout_sec=0.001)
            
            if cv2.waitKey(1) & 0xFF == 27:
                break
    
    except KeyboardInterrupt:
        pass
    
    finally:
        if node.visualize:
            cv2.destroyAllWindows()
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
